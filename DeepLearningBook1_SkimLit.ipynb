{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningBook1-SkimLit.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0Hk77zWNkQpK",
        "cNWHpv_cmqyX",
        "Q9ODFXfm2m9h",
        "boLmC9O9ALx7",
        "wanWMilg-f3a",
        "2d32tch7vVpI",
        "FkpYeqcowRcI",
        "FhtBD0TGyru9",
        "LwCcvd6SGGCz",
        "fft9YAM7GSnm",
        "M-6V60I0Hgkf",
        "GXrUz7GHIa3w",
        "fH6uR6EY-sjj",
        "frSFQn5iBfFr",
        "tyII34XlCObT",
        "Cs6U53rrDlz0",
        "NMMeYmwHY23r",
        "YD40uWDQbKmz",
        "5-imqdRBGT8y",
        "eiK4NfbVJ2_-",
        "K65qxZt0KonS",
        "S86z32EEvU0g",
        "aw7HxLspxw0a"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNhA431Ev+bqgWR7AzAgHnI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mthakur08/Deep_Learning_Skim_Lit/blob/main/DeepLearningBook1_SkimLit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Milestone Project 2 - Skimlit\n",
        "\n",
        "\n",
        "*   The purpose of this project is to make reading medical abstracts \n",
        "easier (the source of the dataset is available : https://arxiv.org/abs/1710.06071).\n",
        "*   And reading through the paper above, we see that the model architecture that they were using to get the best results is available here: https://arxiv.org/abs/1612.05251\n",
        "*   ðŸ“š **Resource** If you want to see the ground truth for this note book (with lots of diagrams and annotations) see the GitHub: https://github.com/mrdbourke/tensorflow-deep-learning.\n",
        "                         "
      ],
      "metadata": {
        "id": "gqmlJrHkehRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm access to a GPU\n"
      ],
      "metadata": {
        "id": "0Hk77zWNkQpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvDvyoJplh2A",
        "outputId": "b8a4e5d9-fa86-4ca4-a1d9-3b0da0ede7a2"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data\n",
        "\n",
        "> Since we'll be replicating the paper above (PubMed 200K RCT), let's download the dataset they used\n",
        "\n",
        "> We can do so from the author's GitHub: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "cNWHpv_cmqyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOvEhJ4xn1lF",
        "outputId": "e0e99b14-8d1e-47ac-cd9f-f62bef5c89ed"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in the PubMed-20K dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z33gAtUqeFK",
        "outputId": "95ea2fb6-0f78-4f08-f154-781487c6e560"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Start our experiments using the 20K dataset with numbers replaced by the at sign\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "nRVj-K71sEtO"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check all of the filenames inthe target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PapMkrPCs0D5",
        "outputId": "a2ca3144-63fd-45cc-bfa7-9d38fe7f260c"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to read the lines of a document\n",
        "\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads a filename (a text filename) and returns the lines of a text as a list.\n",
        "\n",
        "  Args:\n",
        "    filename: a string containing he target filepath.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "  \"\"\"    \n",
        "  with open(filename, \"r\") as f:\n",
        "      return f.readlines() #read how to read text files in python\n"
      ],
      "metadata": {
        "id": "QZraFJgvunPV"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read in the training lines\n",
        "train_lines = get_lines(data_dir+\"train.txt\") #read the lines within the training file\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQWF-DJdwWna",
        "outputId": "978f8991-09ea-4520-d976-4c54d1bb3894"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Let's plan our pre-processing"
      ],
      "metadata": {
        "id": "Q9ODFXfm2m9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the length of the data\n",
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKtifwXuyRcG",
        "outputId": "f972ccab-a3f0-48ce-a340-03b5371484bb"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Let's think about how we want our data to look...\n",
        "*   How I think out data would be best represented...\n",
        "\n",
        "â­ We want to retrun a _**list of dictionaries**_ which is compatible with _**pandas**_:\n",
        "\n",
        "```\n",
        "[{'line number': 0,\n",
        "  'target': \"BACKGROUND\"\n",
        "  'text': \"Emotional eating is associated with overeating and the development of obesity .\\n\",\n",
        "  'total_lines': 11}]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "YcNWf5fCyYlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lets write a function which turn each of our data into the above format so we can continue to progress"
      ],
      "metadata": {
        "id": "boLmC9O9ALx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence\n",
        "  number the target line is.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) #get all the lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  #Loop through each lines in the target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): #check to see if the line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" #reset the abstract string if the line is an ID line\n",
        "    elif line.isspace():\n",
        "      abstract_line_split = abstract_lines.splitlines() #split abstract into separate lines\n",
        "\n",
        "      #iterate through each line in a single abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} #create an empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") #split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] #get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() #get target text and lower case\n",
        "        line_data[\"line_number\"] = abstract_line_number #what number does the line appear in the abstract\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 #how many total lines are there (we want to start from 0 - thats why we subtract 1)\n",
        "        abstract_samples.append(line_data)#add line data dictionnary to abstract_samples list so we can return it\n",
        "    else: #if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  \n",
        "  return abstract_samples\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4CgS_oB1x1SA"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess our Data"
      ],
      "metadata": {
        "id": "wanWMilg-f3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")#dev is another name for validation\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8Y4h_fZ6N0F",
        "outputId": "248465f5-5ec3-4dbe-f7d1-edf742de73cd"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 752 ms, sys: 140 ms, total: 892 ms\n",
            "Wall time: 908 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chech the first few abstracts of our trainingdata\n",
        "train_samples[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o17l1VEK7CjE",
        "outputId": "680ab78b-53cc-4878-f3c9-d6903b487e75"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11}]"
            ]
          },
          "metadata": {},
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize the data as a Pandas DataFrame\n",
        "\n"
      ],
      "metadata": {
        "id": "2d32tch7vVpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn our dictionary into pandas dataframe to visualize it\n",
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "83UteyKg9Bw8",
        "outputId": "2e45ef2d-5b50-4015-ba3e-41279b83d9de"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e44c5c2-462e-4651-97fe-0eb0c31bf4ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e44c5c2-462e-4651-97fe-0eb0c31bf4ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e44c5c2-462e-4651-97fe-0eb0c31bf4ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e44c5c2-462e-4651-97fe-0eb0c31bf4ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check districution of labels\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEKQLpc6uD8j",
        "outputId": "85aeff25-c8fa-41e5-bce0-e0386ad6a8bc"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the length of different lines\n",
        "train_df.total_lines.plot.hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "nHCggr0BvA0l",
        "outputId": "1499f242-897d-4833-d22a-902d30a85fe3"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff7843a64d0>"
            ]
          },
          "metadata": {},
          "execution_count": 258
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get lists of sentences"
      ],
      "metadata": {
        "id": "FkpYeqcowRcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDdqzs1ywUln",
        "outputId": "8bf9bc6f-2566-4b2b-b4e3-2c6edb099a45"
      },
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out 1st 10 samples of train_sentences\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1DSg_Bmx9ls",
        "outputId": "7d7407a7-254f-4818-a39c-af594dc61188"
      },
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Turning out target labels into numbers"
      ],
      "metadata": {
        "id": "FhtBD0TGyru9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###One Hot Encode"
      ],
      "metadata": {
        "id": "LwCcvd6SGGCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode labels\n",
        "# sklearn has one hot encoder\n",
        "import sklearn\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#one_hot_encode\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "#sparce = False forces it as a dense(not sparse) matrix which uses more memory (tensorflow doesn't run on sparse matrices)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "#you have to reshape to (-1,1) otherwise shape error \n",
        "#fit_transform does the one hot encoding; once you've fit_transform on train_labels, you can just transform the val_labels and test_labels\n",
        "#its not necessary to fit anymore, thats already done\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1,1))"
      ],
      "metadata": {
        "id": "5RWCkBQKyiZg"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets see how it looks\n",
        "train_labels_one_hot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaKaNRw_F1E9",
        "outputId": "22e3131f-8652-453c-bc10-c45c511502f9"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Label Encode labels"
      ],
      "metadata": {
        "id": "fft9YAM7GSnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())"
      ],
      "metadata": {
        "id": "MV_0YEx7GXiq"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see how this look likes\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7m81UbBHE1M",
        "outputId": "eb83149c-8b49-41d4-8229-47ef4e30bdf4"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get class names and map it back from LabelEncoder instance"
      ],
      "metadata": {
        "id": "M-6V60I0Hgkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "#dont forget the underscore after classes\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oOBm21-HzN5",
        "outputId": "6020277e-5c23-4c61-9afd-5144dcb2f1dc"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 0 (Baseline)\n",
        "*   Naive Bayes TF-IDF Explorer (used in text)\n",
        "*   A good/basic explanation of Bayes Theorem: https://www.youtube.com/watch?v=Q8l0Vip5YUw\n",
        "*   Formula for Naive Bayes theorem (conditional probability for A, given that B has occurred):\n",
        "\n",
        "\\begin{align}\n",
        "        P(A \\mid B) = \\frac{P(B \\mid A) \\, P(A)}{P(B)}\n",
        "    \\end{align}\n",
        "\n",
        "*   Go to Scikit learn Machine learning map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html to help decide which baseline model to choose\n",
        "*   The following article explains tfidf: http://tfidf.com\n",
        "TF-IDF is a way to assesss the importance of a word look at frequency of occurence increased frequency \n",
        "means increased importance, but it is off set by the frequency accross more documents so that\n",
        "words like as, and, in, of, etc.  have diminished importance in the final  analysis\n",
        "*   The formula for TF-IDF:\n",
        "    1.   TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
        "    2.   IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
        "    3.   TF(t) * IDF(t)\n",
        "*   Check out Chris Albon website: https://chrisalbon.com"
      ],
      "metadata": {
        "id": "GXrUz7GHIa3w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer: Converts a collection of raw documents to a matrix of TF-IDF features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# MultinomialNB is a Naive Bayes classifier for multinomial models.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# The model is created within a pipeline from sklearn\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "nvVnCPjPId6y"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create a SKLearn Pipeline and Fit the Data\n",
        "\n"
      ],
      "metadata": {
        "id": "fH6uR6EY-sjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the Pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tf-idf\", TfidfVectorizer()),\n",
        "                    (\"clf\", MultinomialNB())\n",
        "])\n",
        "# fit the pipeline to the training data\n",
        "#Multinomial currently does not accept one hot encoded, only encoded\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHcUFHf8-xyZ",
        "outputId": "af931615-0d2d-4c99-d87e-a2147ebebc55"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Score(Evaluate) our model"
      ],
      "metadata": {
        "id": "frSFQn5iBfFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SKLearn uses score not evaluate as in Keras; returns accuracy as the metric\n",
        "print(f\"The accuracy of our model bassed on validation data is {round(model_0.score(X=val_sentences, y=val_labels_encoded),3)}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDnphnvMBps1",
        "outputId": "4eeb88d7-f5bd-4c50-9ed1-ee6c67d65e2f"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of our model bassed on validation data is 0.722.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make predicitons using our baseline model"
      ],
      "metadata": {
        "id": "tyII34XlCObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# returns an array of numerical labels \n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y50kGIkPCd7-",
        "outputId": "fccbba51-368e-4c1f-e414-3ee7ca2bebb3"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check val_labels_encoded\n",
        "val_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrk7t0GjDEWj",
        "outputId": "cb94da10-b87a-434d-d4eb-8e1cd8a26353"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ§¤ Helper Function: calculate_results()\n",
        "\n",
        "*   Calculates model accuracy, precision, recall, and f1 score of a binary classsification model."
      ],
      "metadata": {
        "id": "Cs6U53rrDlz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall, and f1 score of a binary classsification model.\n",
        "\n",
        "    Args:\n",
        "        y_true: true labels in the form of a 1d array.\n",
        "        y_pred: predicted labels in the form of a 1d array.\n",
        "\n",
        "    Returns a dictionary of accuracy, precision, recall, and f1-score.\n",
        "    \"\"\"\n",
        "    # Calculate model_accuracy\n",
        "    model_accuracy = accuracy_score(y_true,y_pred)*100\n",
        "    # Calculate model_precision, recall, and f1-score using weighted average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    model_results = {\"accuracy\":model_accuracy,\n",
        "                     \"precision\": model_precision,\n",
        "                     \"model_recall\": model_recall,\n",
        "                     \"model_f1\": model_f1}\n",
        "    return model_results\n"
      ],
      "metadata": {
        "id": "dD7g3vZIFsfU"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate baseline results"
      ],
      "metadata": {
        "id": "NMMeYmwHY23r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                         y_pred=baseline_preds)\n",
        "for k, v in baseline_results.items():\n",
        "    print(k, '=', round(v,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s1Zj2sBY9Tv",
        "outputId": "fa9d03e7-246e-4d95-98a6-2fabac45fa7e"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 72.183\n",
            "precision = 0.719\n",
            "model_recall = 0.722\n",
            "model_f1 = 0.699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 - Conv1d"
      ],
      "metadata": {
        "id": "mabSKPhAafQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing our data (the text) for deep sequence models"
      ],
      "metadata": {
        "id": "YhtshYl4al0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Vectorization and Embedding Layers - Preparation"
      ],
      "metadata": {
        "id": "YD40uWDQbKmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "WMIkxmasbf64"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#how long is each sentence on average\n",
        "# the following takes a list of sentences(train_sentences) and splits it to token level\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = round(np.mean(sent_lens),2)\n",
        "print(f\" Our average sentence length is {avg_sent_len} words.\")\n",
        "                 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwGnh00PcWSN",
        "outputId": "12c69e21-06a8-4f97-e29d-2455578e5ab1"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Our average sentence length is 26.34 words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average tells you how long and whether you need to pad or truncate"
      ],
      "metadata": {
        "id": "3u98vw4Edudt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "Tlf-eBBfdoWh",
        "outputId": "4d9a1918-7276-4f33-e1d6-84005fb6f900"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.1050e+03, 3.5170e+03, 7.7850e+03, 1.3079e+04, 1.6589e+04,\n",
              "        1.8463e+04, 1.8770e+04, 1.7656e+04, 1.5580e+04, 1.3302e+04,\n",
              "        1.1002e+04, 9.0040e+03, 7.0390e+03, 5.5540e+03, 4.2780e+03,\n",
              "        3.3890e+03, 2.7020e+03, 2.1960e+03, 1.7050e+03, 9.5300e+02,\n",
              "        1.1780e+03, 9.0000e+02, 7.5000e+02, 6.0900e+02, 4.9400e+02,\n",
              "        4.0100e+02, 3.5000e+02, 2.5000e+02, 2.2900e+02, 2.1500e+02,\n",
              "        1.6700e+02, 1.2600e+02, 1.0200e+02, 1.0100e+02, 6.4000e+01,\n",
              "        6.1000e+01, 5.5000e+01, 4.5000e+01, 4.0000e+01, 2.5000e+01,\n",
              "        2.5000e+01, 2.4000e+01, 2.2000e+01, 1.4000e+01, 1.6000e+01,\n",
              "        1.0000e+01, 7.0000e+00, 1.6000e+01, 7.0000e+00, 5.0000e+00,\n",
              "        3.0000e+00, 5.0000e+00, 5.0000e+00, 6.0000e+00, 1.0000e+00,\n",
              "        3.0000e+00, 1.0000e+00, 4.0000e+00, 4.0000e+00, 0.0000e+00,\n",
              "        3.0000e+00, 0.0000e+00, 1.0000e+00, 2.0000e+00, 3.0000e+00,\n",
              "        3.0000e+00, 0.0000e+00, 2.0000e+00, 4.0000e+00, 1.0000e+00,\n",
              "        0.0000e+00, 3.0000e+00, 2.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
              " array([  1.  ,   3.95,   6.9 ,   9.85,  12.8 ,  15.75,  18.7 ,  21.65,\n",
              "         24.6 ,  27.55,  30.5 ,  33.45,  36.4 ,  39.35,  42.3 ,  45.25,\n",
              "         48.2 ,  51.15,  54.1 ,  57.05,  60.  ,  62.95,  65.9 ,  68.85,\n",
              "         71.8 ,  74.75,  77.7 ,  80.65,  83.6 ,  86.55,  89.5 ,  92.45,\n",
              "         95.4 ,  98.35, 101.3 , 104.25, 107.2 , 110.15, 113.1 , 116.05,\n",
              "        119.  , 121.95, 124.9 , 127.85, 130.8 , 133.75, 136.7 , 139.65,\n",
              "        142.6 , 145.55, 148.5 , 151.45, 154.4 , 157.35, 160.3 , 163.25,\n",
              "        166.2 , 169.15, 172.1 , 175.05, 178.  , 180.95, 183.9 , 186.85,\n",
              "        189.8 , 192.75, 195.7 , 198.65, 201.6 , 204.55, 207.5 , 210.45,\n",
              "        213.4 , 216.35, 219.3 , 222.25, 225.2 , 228.15, 231.1 , 234.05,\n",
              "        237.  , 239.95, 242.9 , 245.85, 248.8 , 251.75, 254.7 , 257.65,\n",
              "        260.6 , 263.55, 266.5 , 269.45, 272.4 , 275.35, 278.3 , 281.25,\n",
              "        284.2 , 287.15, 290.1 , 293.05, 296.  ]),\n",
              " <a list of 100 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 275
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use numpy.percentile - how long of a sentence length covers 95% of example - \n",
        "#use this to decide where to truncate/pad\n",
        "output_seq_length = int(np.percentile(sent_lens, 95))\n",
        "print(f\"The length of sentence which covers 95% of our samples: {output_seq_length}.\")"
      ],
      "metadata": {
        "id": "IYa_hbUDeUAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365dc8a4-1e1e-48e7-fcd1-a73786c05224"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of sentence which covers 95% of our samples: 55.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use 55 as length for sentences"
      ],
      "metadata": {
        "id": "9y4JA9sxfXzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check max, min, mean, median length\n",
        "print(f\" Maximum sentence length = {max(sent_lens)}\\n\",\n",
        "      f\"Minimum sentence length = {min(sent_lens)}\\n\", \n",
        "      f\"Average sentence length = {round(np.mean(sent_lens), 2)}\\n\",\n",
        "      f\"Median sentence length = {np.median(sent_lens)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2uATXTseipV",
        "outputId": "d72ac69f-fb09-4a70-ad16-57dcbcf3829a"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Maximum sentence length = 296\n",
            " Minimum sentence length = 1\n",
            " Average sentence length = 26.34\n",
            " Median sentence length = 23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "296 words in max sentence length.\n",
        "Can't use 296 as that is too long for our analysis - most data will be padded and that won't be an efficient use of computing power.  55 will cover 95% of sentences"
      ],
      "metadata": {
        "id": "vVdH5iIhfhEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create text vectorizer layer\n",
        "The documentation for the keras text vectorizer:\n",
        "https://keras.io/api/layers/preprocessing_layers/core_preprocessing_layers/text_vectorization/"
      ],
      "metadata": {
        "id": "5-imqdRBGT8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create the text vectorizer\n",
        "#max_tokens is the most common vocab out of your set (everything else is OOV - out of vocabulary)\n",
        "#the paper tells us that the max voc size is 60,000 \n",
        "#taken from table 2 in http://arvix.org/pdf/1710.06071.pdf\n",
        "max_tokens = 68000\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
        "                                    output_sequence_length = output_seq_length,\n",
        "                                    pad_to_max_tokens=True\n",
        "                                    )\n",
        "# max_tokens = number of words in vocabulary (obtained from paper)\n",
        "# output_sequence_length is the sentence length that we determined earlier(55)\n",
        "# which will cover 95% of sentences\n",
        "# leave other parameterss as default"
      ],
      "metadata": {
        "id": "FVQEW-bIGzaZ"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adapt text vectorizer to training data"
      ],
      "metadata": {
        "id": "eiK4NfbVJ2_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adapt only train data and later fit val and test data\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "r2EcQtAVJ6-f"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's test out text Vectorizer\n"
      ],
      "metadata": {
        "id": "K65qxZt0KonS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lets test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\") # Need to get .split() as it maps words, otherwise it will give length of characters\n",
        "print(f\"\\nVectorized text: {text_vectorizer([target_sentence])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ecRVxyuKfqj",
        "outputId": "513ddf28-2253-4ea7-dbe9-b0c3542764f4"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "although non-experimental , this study will generate first large-scale data on the utility of imaging-enhancing algorithms in whole-body mdct for major blunt trauma .\n",
            "\n",
            "Length of text: 24\n",
            "\n",
            "Vectorized text: [[  311 25517    23    17    95  5440   152  4027   100    18     2  2049\n",
            "      4 55347  4608     5  4734  6635    11   347  6313  1564     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above output, the vectorized array, maps words to their frequency (e.g. \"and\" is 3).  It drops punctuations and numbers.  The rest is padded with 0s up to 55."
      ],
      "metadata": {
        "id": "uwaQCSCGOERf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How many words in our training Vocabulary\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary : {len(rct_20k_text_vocab)}\")\n",
        "print(f\"Most common words : {rct_20k_text_vocab[:5]}\") #vectorizer automatically sorts by frequency\n",
        "print(f\"Least common words : {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR9XN6xBOY_R",
        "outputId": "a7a50b9a-25a9-4b73-8331-704c7f5880b6"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocabulary : 64841\n",
            "Most common words : ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words : ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS7bZep5Rd5V",
        "outputId": "1e522d73-ddbe-4ee9-c2d0-e4f8a485bcec"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'idf_weights': None,\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization_3',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': True,\n",
              " 'ragged': False,\n",
              " 'sparse': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create custom text embedding"
      ],
      "metadata": {
        "id": "S86z32EEvU0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create token embedding layer\n",
        "# input-dim is the length of the vocab\n",
        "# output_dim - this is user set, multiple of 8 preferred\n",
        "# mask_zero - this masks zero padding to save space (when there are lots of zeros)\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                               output_dim=128,\n",
        "                               mask_zero=True\n",
        "                               )"
      ],
      "metadata": {
        "id": "Cj2AO4vlvZ93"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Show embedding as an example with a random sentence\n"
      ],
      "metadata": {
        "id": "aw7HxLspxw0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sentence before vectorization:\\n{target_sentence}\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n {vectorized_sentence}\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n {embedded_sentence}\")\n",
        "print(f\"Embedded sentence shape:\\n {embedded_sentence.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvQj4UyGxzxY",
        "outputId": "667f3fe8-64be-4ac3-9e54-1161d8974614"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            "although non-experimental , this study will generate first large-scale data on the utility of imaging-enhancing algorithms in whole-body mdct for major blunt trauma .\n",
            "Sentence after vectorization (before embedding):\n",
            " [[  311 25517    23    17    95  5440   152  4027   100    18     2  2049\n",
            "      4 55347  4608     5  4734  6635    11   347  6313  1564     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "Sentence after embedding:\n",
            " [[[ 0.00693591 -0.00742729 -0.04459256 ... -0.03230357  0.03983481\n",
            "    0.0173936 ]\n",
            "  [-0.01231196 -0.04992813 -0.04221689 ...  0.03938358 -0.00787685\n",
            "    0.03249088]\n",
            "  [-0.03342295  0.00976484  0.0322472  ...  0.01249125 -0.04069443\n",
            "   -0.02671367]\n",
            "  ...\n",
            "  [ 0.0454901  -0.0359956  -0.04036741 ... -0.03350518 -0.02188538\n",
            "    0.02923382]\n",
            "  [ 0.0454901  -0.0359956  -0.04036741 ... -0.03350518 -0.02188538\n",
            "    0.02923382]\n",
            "  [ 0.0454901  -0.0359956  -0.04036741 ... -0.03350518 -0.02188538\n",
            "    0.02923382]]]\n",
            "Embedded sentence shape:\n",
            " (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create a fast loading dataset\n",
        "Making sure the data loads as fast as possible.  Two guides:\n",
        "*   https://www.tensorflow.org/guide/data_performance\n",
        "*   https://www.tensorflow.org/guide/data\n",
        "\n"
      ],
      "metadata": {
        "id": "cMgxJ7Oq0tOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Turn our data into Tensorflow dataset"
      ],
      "metadata": {
        "id": "79x2GxCu5HYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doGXVc2b0yCL",
        "outputId": "ea375778-a258-47df-e18b-d829a4794d74"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#as a review, lets look at our train_labels_one_hot\n",
        "train_labels_one_hot.shape, train_labels_one_hot[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbzBrtby66vz",
        "outputId": "fce43630-5c02-4f67-efec-47e477223386"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((180040, 5), array([0., 0., 0., 1., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Take our datasets and turn them into prefetched datasets for improved performance\n",
        "\n",
        "âœ… Need to read tf performance modules"
      ],
      "metadata": {
        "id": "n63NzzD_7_6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq7kbMM38GVZ",
        "outputId": "30e9bef9-4e3c-4c95-c46d-5354450de3ad"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Conv1d model with token embeddings"
      ],
      "metadata": {
        "id": "d7UJUYGq91R7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s-ldy3wO-IT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DLER1JR7fuO5"
      }
    }
  ]
}